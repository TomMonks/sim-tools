'''
Contains algorithms for Optimisation via Simulation
with an indifference zone framework (fixed precision optimisation)

1. KN - (Kim-Nelson) sequential Ranking and Selection Algorithm

2. KNPlusPlus - Kim and Nelson updated their original KN procedure to 
update the variance estimate of designs at each stage.  

'''

import numpy as np

from ovs.toy_models import (BanditCasino, 
                            GaussianBandit, 
                            guassian_bandit_sequence, 
                            guassian_sequence_model)

class KNPlusPlus(object):
    '''
    KN++ algorithm for Ranking and Selection

    More coordiation than KN. V
    Variances are updated at each stage.

    References.
    http://users.iems.northwestern.edu/~nelsonb/Publications/17KimNelson.pdf
    https://www2.isye.gatech.edu/~skim/KimNelson.pdf 

    '''
    def __init__(self, model, n_designs, delta, alpha=0.05, n_0=2, obj='max'):
        '''
        Constructor method for KN++  Ranking and Selection Procedure.

        Reference = 'TO ADD'

        Parameters:
        ----------

        model - object, simulation model that implements 
        method simulate(design, replications)

        n_designs - int, the number of designs (k)

        delta - float, the indifference zone

        alpha - float, between 0 and 1.  Used to calculate the 1-alpha 
        probability of correct selection

        n_0 - int, the number of initial observations (default = 2)
        
        obj - str, objective 'max' or 'min' (default='max)

        '''
        model.register_observer(self)
        self._env = model

        self._allocations = np.zeros(n_designs, np.int32)
        self._means = np.zeros(n_designs, np.float64)

        #sample variances for each design
        self._vars = np.zeros(n_designs, np.float64)
        #used for calculating running sample variance
        self._sq = np.zeros(n_designs, np.float64)

        #should I also be storing the variances of the differences?

        self._k = n_designs

        #set of non-eliminated systems
        #designs are screened at each stage and removed.
        self._contenders = np.arange(self._k)

        self._delta = delta
        self._alpha = alpha
        self._n_0 = n_0
        self._r = 0

        types = ['min', 'max']
        if obj not in types:
            raise ValueError('obj parameter must be min or max')

        #code set up for max negate for min.
        if obj == 'max':
            self._negate = 1.0
        else:
            self._negate = -1.0

        self._obj = obj


    def _calculate_eta(self):
        return 0.5 * (np.power(2 * (1 - np.power((1 - self._alpha), 1 / (self._k - 1))), -2/(self._n-1)) - 1)

    def __str__(self):
        return f"KN(n_designs={self._k}, delta={self._delta}, alpha={self._alpha}, n_0={self._n_0}, obj={self._obj})"

    def reset(self):
        '''Resets all attributes
        '''
        self._total_reward = 0
        self._allocations = np.zeros(self._k, np.int32)
        self._means = np.zeros(self._k, np.float64)
        self._allocations = np.zeros(self._k, np.int32)
        self._init_obs = np.zeros((self._k, self._n_0), np.float64)
        self._contenders = np.arange(self._k)
        self._vars = np.zeros(self._k, np.float64)
        self._sq = np.zeros(self._k, np.float64)
        self._n = 0


    def solve(self):
        '''Run KN++
        '''
        self.reset()
        self._initialisation()

        while not self._stopping():
            self._screening()
            self._sequential_replication()
            self._update()
            
        return self._contenders

    def _initialisation(self):  
        '''
        Initialise KN++
        
        Estimate initial sample means and variances of the differences

        '''      
        for observation in range(self._n_0):
            self._sequential_replication()

        self._eta = self._calculate_eta()
        self._h_squared = 2 * self._eta * (self._n - 1)

    def _stopping(self):
        '''
        If |I| = 1 then stop (and select the system whose index is in I)
        else take one further sample from each system

        '''
        if len(self._contenders) == 1:
            return True
        
        return False
                
    
    def _sequential_replication(self):
        '''
        Run a single replication of each
        design
        '''
        for design in self._contenders:
            self._env.simulate(design)
        
        self._n += 1

    def _screening(self):
        '''
        Loop through remaining contenders and screen if 
        mean(design_i) < mean(design_j) - epsilon_ij

        where epsilon_ij (w_ij in some papers) determines how far the sample mean 
        from system i can drop below the sample mean of system j without being eliminated.
        '''
        self._contenders_old = np.asarray(self._contenders).copy()
        contenders_mask = np.full(self._contenders.shape, True, dtype=bool)
                  
        #inefficient way to code this...will update to pure numpy at some stage

        for i in range(len(self._contenders_old)):
            for j in range(len(self._contenders_old)):

                if i != j:
                    design_i, design_j = self._contenders_old[i], self._contenders_old[j]
                    w_ij = self._elimination_distance(design_i, design_j)

                    if self._means[design_i] < self._means[design_j] - w_ij:
                        contenders_mask[i] = False
                        break
               
        self._contenders = self._contenders[contenders_mask]


    def _mean_difference(self, design_i, design_j):
        '''diff between two sample means
        '''
        mean_i = self._means[design_i]
        mean_j = self._means[design_j]
        return mean_i - mean_j
       

    def _elimination_distance(self, design_i, design_j):
        '''
        Returns the distance mean(design_i) can fall below mean(design_j)
        before it is ELIMINATED.

        Parameters:
        -----
        design_i - int, the index of the first design
        
        design_j - int, the index of the second design

        Returns:
        --------
        float. 
        '''
        #sample variances
        var_i = self._vars[design_i]
        var_j = self._vars[design_j]
        sum_of_vars = var_i + var_j

        #I think the problem is that I am not using the variance of the differences.
        w_ij = (self._delta / (2 * self._n)) \
            * (((self._h_squared * (sum_of_vars)) / self._delta**2) - self._n)

        #return max(0, w_ij)
        return w_ij


    def _update(self):
        '''update step.
        Recaulcate eta and h_squared
        '''
        self._eta = self._calculate_eta()
        self._h_squared = 2 * self._eta * (self._n - 1)


    def feedback(self, *args, **kwargs):
        '''
        Feedback from the simulated environment
        Recieves an observation from the system

        Parameters:
        ------
        *args -- list of argument
                 0  sender object
                 1. design index to update
                 2. observation

        *kwargs -- dict of keyword arguments

        '''
        design_index = args[1]
        observation = args[2]
        self._allocations[design_index] += 1 
                
        #update running mean and standard deviation of the design
        self._update_sample_estimates(design_index, observation)
        

    def _update_sample_estimates(self, design_index, observation):
        '''
        Updates the running sample mean and var of the design

        Parameters:
        ------
        design_index -- int, index of the array to update

        observation -- float, observation recieved from the last replication
        '''
        n = self._allocations[design_index]
        current_mean = self._means[design_index]
        new_mean = ((n - 1) / float(n)) * current_mean + (1 / float(n)) * observation * self._negate

        if n > 1:
            self._sq[design_index] += (observation - abs(current_mean)) * (observation - abs(new_mean))
            self._vars[design_index] = self._sq[design_index] / (n - 1)

        self._means[design_index] = new_mean    

    

    



class KN(object):
    def __init__(self, model, n_designs, delta, alpha=0.05, n_0=2, obj='max'):
        '''
        Constructor method for KN  Ranking and Selection Procedure.

        This works well for up to 20 competing designs

        References. 
        http://users.iems.northwestern.edu/~nelsonb/Publications/KimNelsonKN.pdf

        Parameters:
        ----------

        model - object, simulation model that implements 
        method simulate(design, replications)

        n_designs - int, the number of designs (k)

        delta - float, the indifference zone

        alpha - float, between 0 and 1.  Used to calculate the 1-alpha 
        probability of correct selection

        n_0 - int, the number of initial observations (default = 2)

        '''
        model.register_observer(self)
        self._env = model

        self._current_round = 0
        self._allocations = np.zeros(n_designs, np.int32)
        self._means = np.zeros(n_designs, np.float64)
        self._init_obs = np.zeros((n_designs, n_0), np.float64)
        
        self._k = n_designs

        #the set of non-eliminated systems I
        self._contenders = np.arange(self._k)

        self._delta = delta
        self._alpha = alpha
        self._n_0 = n_0
        
        #number of replications that has been run.
        self._r = 0

        self._eta = 0.5 * (np.power((2 * alpha) / (self._k - 1), -2/(self._n_0-1)) - 1)

        types = ['min', 'max']
        if obj not in types:
            raise ValueError('obj parameter must be min or max')

        #code set up for max negate for min.
        if obj == 'max':
            self._negate = 1.0
        else:
            self._negate = -1.0

        self._obj = obj


    def __str__(self):
        return f"KN(n_designs={self._k}, delta={self._delta}, alpha={self._alpha}, n_0={self._n_0}, obj={self._obj})"

    def reset(self):
        self._total_reward = 0
        self._allocations = np.zeros(self._k, np.int32)
        self._means = np.zeros(self._k, np.float64)
        self._allocations = np.zeros(self._k, np.int32)
        self._init_obs = np.zeros((self._k, self._n_0), np.float64)
        self._contenders = np.arange(self._k)
        self._r = 0
    
    def solve(self):
        '''Run procedure KN
        '''
        self.reset()
        self._initialisation()

        while not self._stopping():
            self._screening()
            self._sequential_replication()

        return self._contenders

    def _initialisation(self):  
        '''
        Initialise KN
        
        Estimate initial sample means and variances of the differences

        '''      
        self._h_squared = 2 * self._eta * (self._n_0 - 1)
        
        for observation in range(self._n_0):
            self._sequential_replication()
                
        self._variance_of_diffs = self._calc_variance_of_differences()

    def _sequential_replication(self):
        for design in self._contenders:
            self._env.simulate(design)
        
        self._r += 1

    def _calc_variance_of_differences(self):
        pairwise_diffs = self._init_obs[:, None] - self._init_obs
        variance_of_diffs = pairwise_diffs.var(axis=-1, ddof=1)
        #flattens array and drops differences with same design
        return variance_of_diffs[~np.eye(variance_of_diffs.shape[0],dtype=bool)]

    #need to check if this is correct...
    #possibly a bug.  Works when in designs are ordered, but not otherwise...
    #think this is fixed 28/02/2020 TM - to double check.
    def _screening(self):
        self._contenders_old = np.asarray(self._contenders).copy()
        contenders_mask = np.full(self._contenders.shape, True, dtype=bool)
        #terrible way to code this...!

        #designs in contention for this round
        for i in range(len(self._contenders_old)):
            for l in range(len(self._contenders_old)):
                if i != l:
                    design_i, design_l = self._contenders_old[i], self._contenders_old[l]

                    if not self._design_still_in_contention(design_i, design_l):
                        contenders_mask[i] = False
                        break
                

        self._contenders = self._contenders[contenders_mask]


    def _design_still_in_contention(self, design_i, design_l):
        w_il = self._limit_to_distance_from_sample_means(design_i, design_l)

        mean_i = self._means[design_i]
        mean_l = self._means[design_l]

        return mean_i >= mean_l - w_il

    def _limit_to_distance_from_sample_means(self, design_i, design_l):
        '''
        calculates W_li(r), 
        which determines how far the sample mean from system i can 
        drop below the sample means of system l without being eliminated
        '''
        #note - variance_of_diffs is a flat array for all comparisons and
        #requires this formaula to look up the value.
        index = design_i * (self._k - 1) + (design_l - 1)

        w_il = (self._delta / (2 * self._r)) \
            * (((self._h_squared * self._variance_of_diffs[index]) / self._delta**2) - self._r)
        
        return max(0, w_il)

    def _stopping(self):
        '''
        If |I| = 1 then stop (and select the system whose index is in I)
        else take one further sample from each system

        '''
        if len(self._contenders) == 1:
            return True
        
        return False

    def feedback(self, *args, **kwargs):
        '''
        Feedback from the environment
        Recieves a reward and updates understanding
        of an arm

        Keyword arguments:
        ------
        *args -- list of argument
                 0  sender object
                 1. design index to update
                 2. observation

        *kwards -- dict of keyword arguments:
                   None expected!

        '''
        design_index = args[1]
        observation = args[2]
        self._allocations[design_index] +=1 
        self._means[design_index] = self.updated_mean_estimate(design_index, observation)
        if self._r < self._n_0:
            self._init_obs[design_index][self._r] = observation
        
        
        
    def updated_mean_estimate(self, design_index, observation):
        '''
        Calculate the new running average of the design

        Keyword arguments:
        ------
        design_index -- int, index of the array to update
        observation -- float, observation recieved from the last action

        Returns:
        ------
        float, the new mean estimate for the selected arm
        '''
        n = self._allocations[design_index]
        current_value = self._means[design_index]
        new_value = ((n - 1) / float(n)) * current_value + (1 / float(n)) * observation * self._negate
        return new_value 

    






